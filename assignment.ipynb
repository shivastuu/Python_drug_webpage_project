{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scraping drug data...\n",
      "Cleaning drug data...\n",
      "Saving data to SQLite database...\n",
      "Performing SQL analysis...\n",
      "\n",
      "Top 5 Drugs with 'Severe' in Side Effects:\n",
      "            Drug                                         SideEffect\n",
      "0       Keytruda  the most common side effects of keytruda when ...\n",
      "1  Ciprofloxacin  get emergency medical help if you have signs o...\n",
      "2    Doxycycline  common doxycycline side effects, the most comm...\n",
      "3      Imbruvica  common side effects of imbruvica, common imbru...\n",
      "4        Januvia  get emergency medical help if you have signs o...\n",
      "\n",
      "Average Number of Side Effects per Drug: 42.06\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import sqlite3\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "\n",
    "DATABASE = \"drug_data.db\"\n",
    "NUM_THREADS = 10  # Adjust based on system capability\n",
    "\n",
    "# Step 1: Scraping Drug Data\n",
    "def fetch_page(letter):\n",
    "    \"\"\"Fetch a single page of drugs for a given letter.\"\"\"\n",
    "    base_url = \"https://www.drugs.com/drug_information.html\"\n",
    "    letter_url = f\"{base_url}?letter={letter}\"\n",
    "    response = requests.get(letter_url)\n",
    "    soup = BeautifulSoup(response.content, \"html.parser\")\n",
    "    drug_list_section = soup.find(\"ul\", {\"class\": \"ddc-list-column-4\"})\n",
    "    if drug_list_section:\n",
    "        drug_links = [f\"https://www.drugs.com{link['href']}\" for link in drug_list_section.find_all(\"a\", href=True)[:50]]\n",
    "        return drug_links\n",
    "    return []\n",
    "\n",
    "def fetch_drug_data(drug_url):\n",
    "    \"\"\"Fetch details for a single drug.\"\"\"\n",
    "    response = requests.get(drug_url)\n",
    "    soup = BeautifulSoup(response.content, \"html.parser\")\n",
    "    drug_name = soup.find(\"h1\").text.strip() if soup.find(\"h1\") else \"N/A\"\n",
    "    uses_tag = soup.find(\"h2\", string=lambda text: text and \"What is\" in text)\n",
    "    uses = uses_tag.find_next(\"p\").text.strip() if uses_tag and uses_tag.find_next(\"p\") else \"N/A\"\n",
    "    side_effects = []\n",
    "    side_effects_tag = soup.find(\"h2\", id=\"side-effects\")\n",
    "    if side_effects_tag:\n",
    "        element = side_effects_tag.find_next_sibling()\n",
    "        while element:\n",
    "            if element.name == \"h2\":\n",
    "                break\n",
    "            side_effects.append(element.text.strip())\n",
    "            element = element.find_next_sibling()\n",
    "    side_effects = \", \".join(side_effects) if side_effects else \"N/A\"\n",
    "    return {\"Drug\": drug_name, \"Uses\": uses, \"SideEffect\": side_effects}\n",
    "\n",
    "def scrape_drugs_parallel():\n",
    "    \"\"\"Scrape drugs using multithreading.\"\"\"\n",
    "    drugs_data = []\n",
    "    letters = list(\"ABCDEFGHIJKLMNOPQRSTUVWXYZ\")\n",
    "    \n",
    "    # Fetch drug links in parallel\n",
    "    with ThreadPoolExecutor(max_workers=NUM_THREADS) as executor:\n",
    "        all_drug_links = executor.map(fetch_page, letters)\n",
    "    \n",
    "    # Flatten the list of drug links\n",
    "    all_drug_links = [link for links in all_drug_links for link in links]\n",
    "    \n",
    "    # Fetch drug details in parallel\n",
    "    with ThreadPoolExecutor(max_workers=NUM_THREADS) as executor:\n",
    "        drugs_data = list(executor.map(fetch_drug_data, all_drug_links))\n",
    "    \n",
    "    return pd.DataFrame(drugs_data)\n",
    "\n",
    "# Step 2: Cleaning Data\n",
    "def clean_data(df):\n",
    "    df[\"Drug\"] = df[\"Drug\"].str.replace(r\"[^a-zA-Z0-9\\s]\", \"\", regex=True).str.strip()\n",
    "    df[\"Uses\"] = df[\"Uses\"].str.lower()\n",
    "    df[\"SideEffect\"] = df[\"SideEffect\"].str.lower()\n",
    "    df[\"SideEffectCount\"] = df[\"SideEffect\"].apply(lambda x: len(x.split(\", \")) if x != \"n/a\" else 0)\n",
    "    df.drop_duplicates(subset=[\"Drug\"], inplace=True)\n",
    "    return df\n",
    "\n",
    "# Step 3: SQL Analysis\n",
    "def save_to_sqlite(df):\n",
    "    conn = sqlite3.connect(DATABASE)\n",
    "    df.to_sql(\"drugs\", conn, if_exists=\"replace\", index=False)\n",
    "    conn.close()\n",
    "\n",
    "def perform_sql_analysis():\n",
    "    conn = sqlite3.connect(DATABASE)\n",
    "    \n",
    "    # Top 5 Drugs with the Highest Mentions of \"Severe\" in Side Effects\n",
    "    severe_query = \"\"\"\n",
    "    SELECT Drug, SideEffect\n",
    "    FROM drugs\n",
    "    WHERE SideEffect LIKE '%severe%'\n",
    "    ORDER BY LENGTH(SideEffect) - LENGTH(REPLACE(SideEffect, 'severe', '')) DESC\n",
    "    LIMIT 5;\n",
    "    \"\"\"\n",
    "    top_severe = pd.read_sql_query(severe_query, conn)\n",
    "    print(\"\\nTop 5 Drugs with 'Severe' in Side Effects:\")\n",
    "    print(top_severe)\n",
    "    \n",
    "    # Average Number of Side Effects per Drug\n",
    "    avg_side_effect_query = \"SELECT AVG(SideEffectCount) AS AverageSideEffects FROM drugs;\"\n",
    "    avg_side_effects = pd.read_sql_query(avg_side_effect_query, conn)\n",
    "    print(f\"\\nAverage Number of Side Effects per Drug: {avg_side_effects['AverageSideEffects'][0]:.2f}\")\n",
    "\n",
    "    conn.close()\n",
    "\n",
    "# Main Execution\n",
    "if __name__ == \"__main__\":\n",
    "    print(\"Scraping drug data...\")\n",
    "    raw_data = scrape_drugs_parallel()\n",
    "    print(\"Cleaning drug data...\")\n",
    "    cleaned_data = clean_data(raw_data)\n",
    "    print(\"Saving data to SQLite database...\")\n",
    "    save_to_sqlite(cleaned_data)\n",
    "    print(\"Performing SQL analysis...\")\n",
    "    perform_sql_analysis()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
