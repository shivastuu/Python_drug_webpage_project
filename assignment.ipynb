{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scraping drug data...\n",
      "Cleaning drug data...\n",
      "Saving data to SQLite database...\n",
      "Performing SQL analysis...\n",
      "Top 5 Most Common Uses:\n",
      "                                                Uses  Frequency\n",
      "0  naltrexone is a prescription medication used t...          1\n",
      "1  mounjaro (tirzepatide) is used for type 2 diab...          1\n",
      "2  metoprolol is a beta-blocker that affects the ...          1\n",
      "3  methotrexate interferes with the growth of cer...          1\n",
      "4  methadone is a long-acting opioid medication t...          1\n",
      "\n",
      "Most Frequent Side Effect: None found.\n",
      "\n",
      "Count of Unique Drug Names:\n",
      "Total Unique Drugs: 50\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import sqlite3\n",
    "import time\n",
    "\n",
    "# Step 1: Scraping Drug Data\n",
    "\n",
    "def scrape_drugs():\n",
    "    base_url = \"https://www.drugs.com/drug_information.html\"\n",
    "    response = requests.get(base_url)\n",
    "    soup = BeautifulSoup(response.content, \"html.parser\")\n",
    "\n",
    "    drug_list_section = soup.find(\"ul\", {\"class\": \"ddc-list-column-4\"})\n",
    "    if not drug_list_section:\n",
    "        print(\"Drug list section not found.\")\n",
    "        return pd.DataFrame()\n",
    "\n",
    "    drug_links = [link[\"href\"] for link in drug_list_section.find_all(\"a\", href=True)[:50]]\n",
    "    drugs_data = []\n",
    "    for link in drug_links:\n",
    "        drug_url = f\"https://www.drugs.com{link}\"\n",
    "        drug_info = scrape_drug_info(drug_url)\n",
    "        drugs_data.append(drug_info)\n",
    "        time.sleep(1)  # Avoid overloading the server\n",
    "    return pd.DataFrame(drugs_data)\n",
    "\n",
    "def scrape_drug_info(url):\n",
    "    response = requests.get(url)\n",
    "    soup = BeautifulSoup(response.content, \"html.parser\")\n",
    "    drug_name = soup.find(\"h1\").text.strip() if soup.find(\"h1\") else \"N/A\"\n",
    "    uses_tag = soup.find(\"h2\", string=lambda text: text and \"What is\" in text)\n",
    "    uses = uses_tag.find_next(\"p\").text.strip() if uses_tag and uses_tag.find_next(\"p\") else \"N/A\"\n",
    "    side_effects = []\n",
    "    side_effects_tag = soup.find(\"h2\", id=\"side-effects\")\n",
    "    if side_effects_tag:\n",
    "        element = side_effects_tag.find_next_sibling()\n",
    "        while element:\n",
    "            if element.name == \"h2\":\n",
    "                break\n",
    "            side_effects.append(element.text.strip())\n",
    "            element = element.find_next_sibling()\n",
    "    side_effects = \", \".join(side_effects) if side_effects else \"N/A\"\n",
    "    return {\"Drug\": drug_name, \"Uses\": uses, \"SideEffect\": side_effects}\n",
    "\n",
    "# Step 2: Cleaning Data\n",
    "\n",
    "def clean_data(df):\n",
    "    df[\"Drug\"] = df[\"Drug\"].str.replace(r\"[^a-zA-Z0-9\\s]\", \"\", regex=True).str.strip()\n",
    "    df[\"Uses\"] = df[\"Uses\"].str.lower()\n",
    "    df[\"SideEffect\"] = df[\"SideEffect\"].str.lower()\n",
    "    df.drop_duplicates(subset=[\"Drug\"], inplace=True)\n",
    "    return df\n",
    "\n",
    "# Step 3: SQL Analysis\n",
    "\n",
    "DATABASE = \"drug_data.db\"\n",
    "\n",
    "def save_to_sqlite(df):\n",
    "    conn = sqlite3.connect(DATABASE)\n",
    "    cursor = conn.cursor()\n",
    "    # Create the table if it doesn't exist\n",
    "    cursor.execute('''\n",
    "        CREATE TABLE IF NOT EXISTS drugs (\n",
    "            id INTEGER PRIMARY KEY AUTOINCREMENT,\n",
    "            Drug TEXT NOT NULL,\n",
    "            Uses TEXT NOT NULL,\n",
    "            SideEffect TEXT\n",
    "        );\n",
    "    ''')\n",
    "    conn.commit()\n",
    "\n",
    "    # Insert data into the table\n",
    "    df.to_sql(\"drugs\", conn, if_exists=\"replace\", index=False)\n",
    "    conn.close()\n",
    "\n",
    "def perform_sql_analysis():\n",
    "    conn = sqlite3.connect(DATABASE)\n",
    "\n",
    "    # 1. Top 5 Most Common Uses\n",
    "    top_uses_query = \"\"\"\n",
    "    SELECT Uses, COUNT(*) AS Frequency\n",
    "    FROM drugs\n",
    "    WHERE Uses != 'n/a'\n",
    "    GROUP BY Uses\n",
    "    ORDER BY Frequency DESC\n",
    "    LIMIT 5;\n",
    "    \"\"\"\n",
    "    top_uses = pd.read_sql_query(top_uses_query, conn)\n",
    "    print(\"Top 5 Most Common Uses:\")\n",
    "    print(top_uses)\n",
    "\n",
    "    # 2. Most Frequent Side Effect\n",
    "    side_effect_query = \"\"\"\n",
    "    WITH SplitSideEffects AS (\n",
    "        SELECT TRIM(value) AS SideEffect\n",
    "        FROM json_each(SideEffect)  \n",
    "        WHERE value IS NOT NULL\n",
    "    )\n",
    "    SELECT SideEffect, COUNT(*) AS Frequency\n",
    "    FROM SplitSideEffects\n",
    "    WHERE SideEffect != 'n/a'\n",
    "    GROUP BY SideEffect\n",
    "    ORDER BY Frequency DESC\n",
    "    LIMIT 1;\n",
    "    \"\"\"\n",
    "    try:\n",
    "        most_frequent_side_effect = pd.read_sql_query(side_effect_query, conn)\n",
    "        if not most_frequent_side_effect.empty:\n",
    "            print(\"\\nMost Frequent Side Effect:\")\n",
    "            print(most_frequent_side_effect)\n",
    "        else:\n",
    "            print(\"\\nMost Frequent Side Effect: None found.\")\n",
    "    except Exception as e:\n",
    "        print(f\"Side effect query failed: {e}\")\n",
    "\n",
    "    # 3. Count of Unique Drug Names\n",
    "    unique_drug_count_query = \"SELECT COUNT(DISTINCT Drug) AS UniqueDrugCount FROM drugs;\"\n",
    "    unique_drug_count = pd.read_sql_query(unique_drug_count_query, conn)\n",
    "    print(\"\\nCount of Unique Drug Names:\")\n",
    "    print(f\"Total Unique Drugs: {unique_drug_count['UniqueDrugCount'][0]}\")\n",
    "\n",
    "    conn.close()\n",
    "\n",
    "# Main execution 1\n",
    "if __name__ == \"__main__\":\n",
    "    print(\"Scraping drug data...\")\n",
    "    raw_data = scrape_drugs()\n",
    "    print(\"Cleaning drug data...\")\n",
    "    cleaned_data = clean_data(raw_data)\n",
    "    print(\"Saving data to SQLite database...\")\n",
    "    save_to_sqlite(cleaned_data)\n",
    "    print(\"Performing SQL analysis...\")\n",
    "    perform_sql_analysis()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
